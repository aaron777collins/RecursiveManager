# RecursiveManager Configuration

# Installation
RECURSIVE_MANAGER_HOME=~/.recursive-manager
RECURSIVE_MANAGER_DATA_DIR=~/.recursive-manager/data

# Logging
LOG_LEVEL=info
LOG_FILE=~/.recursive-manager/logs/recursive-manager.log

# Agent Configuration
MAX_AGENT_DEPTH=5
MAX_AGENTS_PER_MANAGER=10
AGENT_TIMEOUT_MS=300000

# Execution
WORKER_POOL_SIZE=5
CONTINUOUS_EXECUTION_INTERVAL_MS=5000

# Framework Adapters
DEFAULT_FRAMEWORK=claude-code
CLAUDE_CODE_PATH=claude

# Database (optional - file-based by default)
# DATABASE_TYPE=sqlite
# DATABASE_PATH=~/.recursive-manager/data/recursive-manager.db

# Notifications (optional)
# SLACK_WEBHOOK_URL=
# DISCORD_WEBHOOK_URL=
# TELEGRAM_BOT_TOKEN=
# TELEGRAM_CHAT_ID=

# GitHub Integration (optional)
# GITHUB_TOKEN=
# GITHUB_REPO=

# ============================================
# AI Provider Configuration
# ============================================

# Multi-Perspective Analysis Provider
# Which provider to use for 8-agent analysis (security, architecture, etc.)
AI_PROVIDER=aiceo-gateway  # Options: aiceo-gateway, anthropic-direct, openai-direct, custom
AI_FALLBACK_PROVIDER=glm-direct  # Fallback if primary unavailable (uses GLM credentials directly)

# --- AICEO Gateway (Recommended for shared quota management) ---
AICEO_GATEWAY_URL=http://localhost:4000/api/glm/submit
AICEO_GATEWAY_API_KEY=your-shared-secret-placeholder
AICEO_GATEWAY_PROVIDER=glm  # Which LLM AICEO should use: glm, anthropic, openai
AICEO_GATEWAY_MODEL=glm-4.7
AICEO_GATEWAY_PRIORITY=high  # high, normal, low

# --- Direct GLM (Fallback if AICEO Gateway down) ---
GLM_API_KEY=your-glm-api-key-placeholder
GLM_API_URL=https://open.bigmodel.cn/api/paas/v4/chat/completions
GLM_MODEL=glm-4.7

# --- Direct Anthropic (Alternative provider) ---
ANTHROPIC_API_KEY=your-anthropic-key-placeholder
ANTHROPIC_API_URL=https://api.anthropic.com/v1/messages
ANTHROPIC_MODEL=claude-sonnet-4-5

# --- Direct OpenAI (Alternative provider) ---
OPENAI_API_KEY=your-openai-key-placeholder
OPENAI_API_URL=https://api.openai.com/v1/chat/completions
OPENAI_MODEL=gpt-4-turbo

# --- Custom Provider ---
CUSTOM_PROVIDER_URL=https://your-custom-endpoint.com/api/chat
CUSTOM_PROVIDER_API_KEY=your-custom-key-placeholder
CUSTOM_PROVIDER_FORMAT=openai  # openai, anthropic, custom

# Agent Execution Provider
# Which provider to use for RecursiveManager agent execution (CEO, CTO, etc.)
AGENT_EXECUTION_PROVIDER=aiceo-gateway  # Options: aiceo-gateway, anthropic-direct
# Note: This uses the same ANTHROPIC_BASE_URL / ANTHROPIC_API_KEY as above

# Analysis Configuration
ANALYSIS_CACHE_TTL_MS=3600000  # 1 hour cache for identical analyses
